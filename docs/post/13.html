<!DOCTYPE html>
<html data-color-mode="light" data-dark-theme="dark_colorblind" data-light-theme="light" lang="zh-CN">
<head>
    <meta content="text/html; charset=utf-8" http-equiv="content-type" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <link href='https://mirrors.sustech.edu.cn/cdnjs/ajax/libs/Primer/21.0.7/primer.css' rel='stylesheet' />
    <script src='https://ai.lxc.one/GmeekVercount.js'></script>
    <link rel="icon" href="https://ai.lxc.one/favicon.png"><script>
        let theme = localStorage.getItem("meek_theme") || "light";
        document.documentElement.setAttribute("data-color-mode", theme);
    </script>
<meta name="description" content="YouTube链接（https://youtu.be/L75N-989B7E
）指向一个时长为1小时43分38秒的视频，标题为《The NVIDIA CEO Jensen Huang | How to Build a Chip, the AI Boom, & U.S.-China Tech | BG2Pod with Brad Gerstner & Bill Gurley》。">
<meta property="og:title" content="英伟达 CEO 黄仁勋 104 分钟访谈 于 2025/9/23">
<meta property="og:description" content="YouTube链接（https://youtu.be/L75N-989B7E
）指向一个时长为1小时43分38秒的视频，标题为《The NVIDIA CEO Jensen Huang | How to Build a Chip, the AI Boom, & U.S.-China Tech | BG2Pod with Brad Gerstner & Bill Gurley》。">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ai.lxc.one/post/13.html">
<meta property="og:image" content="">
<title>英伟达 CEO 黄仁勋 104 分钟访谈 于 2025/9/23</title>



</head>
<style>
body{box-sizing: border-box;min-width: 200px;max-width: 900px;margin: 20px auto;padding: 45px;font-size: 16px;font-family: sans-serif;line-height: 1.25;}
#header{display:flex;padding-bottom:8px;border-bottom: 1px solid var(--borderColor-muted, var(--color-border-muted));margin-bottom: 16px;}
#footer {margin-top:64px; text-align: center;font-size: small;}

</style>

<style>
.postTitle{margin: auto 0;font-size:40px;font-weight:bold;}
.title-right{display:flex;margin:auto 0 0 auto;}
.title-right .circle{padding: 14px 16px;margin-right:8px;}
#postBody{border-bottom: 1px solid var(--color-border-default);padding-bottom:36px;}
#postBody hr{height:2px;}
#cmButton{height:48px;margin-top:48px;}
#comments{margin-top:64px;}
.g-emoji{font-size:24px;}
@media (max-width: 600px) {
    body {padding: 8px;}
    .postTitle{font-size:24px;}
}

</style>
<style>#postBody{font-size:16px}</style>



<body>
    <div id="header">
<h1 class="postTitle">英伟达 CEO 黄仁勋 104 分钟访谈 于 2025/9/23</h1>
<div class="title-right">
    <a href="https://ai.lxc.one" id="buttonHome" class="btn btn-invisible circle" title="首页">
        <svg class="octicon" width="16" height="16">
            <path id="pathHome" fill-rule="evenodd"></path>
        </svg>
    </a>
    
    <a href="https://github.com/lxc-one/lxc-one.github.io/issues/13" target="_blank" class="btn btn-invisible circle" title="Issue">
        <svg class="octicon" width="16" height="16">
            <path id="pathIssue" fill-rule="evenodd"></path>
        </svg>
    </a>
    

    <a class="btn btn-invisible circle" onclick="modeSwitch();" title="切换主题">
        <svg class="octicon" width="16" height="16" >
            <path id="themeSwitch" fill-rule="evenodd"></path>
        </svg>
    </a>

</div>
</div>
    <div id="content">
<div class="markdown-body" id="postBody"><p>YouTube链接（<a href="https://youtu.be/L75N-989B7E" rel="nofollow">https://youtu.be/L75N-989B7E</a><br>
）指向一个时长为1小时43分38秒的视频，标题为《The NVIDIA CEO Jensen Huang | How to Build a Chip, the AI Boom, &amp; U.S.-China Tech | BG2Pod with Brad Gerstner &amp; Bill Gurley》。这是BG2 Podcast的完整访谈，由Altimeter Capital的Brad Gerstner和Benchmark的Bill Gurley主持，采访NVIDIA CEO Jensen Huang（黄仁勋），发布于2025年9月23日。</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/user-attachments/assets/af039887-44a0-4060-bd13-a1ed87767a56"><img width="1080" height="684" alt="Image" src="https://github.com/user-attachments/assets/af039887-44a0-4060-bd13-a1ed87767a56" style="max-width: 100%; height: auto; max-height: 684px;"></a></p>
<h3>视频主要内容概述</h3>
<p>该视频是Jensen Huang与Brad Gerstner和Bill Gurley的深入对谈，涵盖NVIDIA的战略、AI技术的演进、AI工厂（AI Factory）概念、全球技术竞争（特别是美中关系）、以及AI基础设施的能源和规模挑战。访谈围绕NVIDIA如何从芯片设计公司转型为AI革命的核心驱动力，讨论了AI的三大规模法则（Scaling Laws）、10吉瓦级数据中心的“超级赌注”、以及AI对经济和社会的深远影响。Huang还分享了个人经历（作为移民的“美国梦”）和对美国技术领导力的看法，强调加速计算和AI代理（agents）的未来。</p>
<p>视频结构分为多个主题段落，结合技术讲解、行业洞察和地缘政治讨论。以下是主要话题及其在视频中的大致时间点（基于视频内容和章节标记估算，时间点可能因访谈的对话式性质略有浮动）：</p>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>时间点</th>
<th>主要话题</th>
<th>简要描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>0:00 - 5:00</td>
<td>引言与NVIDIA的崛起</td>
<td>主持人介绍背景，回顾NVIDIA从游戏显卡到AI巨头的转型。Huang简述NVIDIA的使命：通过加速计算释放科学潜力。引用：“我们不是卖芯片，我们在加速人类的科学发现。”</td>
</tr>
<tr>
<td>5:00 - 20:00</td>
<td>AI计算的演进与推理热潮</td>
<td>Huang讨论AI从训练到推理（inference）的转变，推理现占NVIDIA营收超40%。预测推理需求将增长“10亿倍”，驱动AI“工业革命”。解释GPU为何优于CPU，强调计算密度的重要性。</td>
</tr>
<tr>
<td>20:00 - 35:00</td>
<td>AI工厂（AI Factory）概念</td>
<td>提出AI工厂的愿景：将电力转化为“智能输出”（如模型推理），类比发电厂。讨论全球数据中心投资已达2万亿美元，AI工厂将重塑生产力。引用：“AI工厂就像发电厂，24/7生产智能。”</td>
</tr>
<tr>
<td>35:00 - 50:00</td>
<td>三大规模法则（3 Scaling Laws）</td>
<td>详解AI发展的三个支柱：1. <strong>预训练（Pre-training）</strong>：构建通用模型，如“大学教育”；2. <strong>后训练（Post-training）</strong>：领域特定优化，如RLHF；3. <strong>测试时计算（Test-time Compute/Inference）</strong>：实时推理，链式思考（Chain-of-Thought）。Huang反驳“规模法则放缓”观点，称AI能力仍在指数级增长。引用：“全世界都错了，AI进步速度比以往更快。”</td>
</tr>
<tr>
<td>50:00 - 1:05:00</td>
<td>10吉瓦超级赌注（10GW Bet）</td>
<td>讨论NVIDIA对超大规模AI数据中心的投资，如支持OpenAI的“Stargate”项目（10吉瓦级，相当于核电站功率）。分析能源瓶颈、供应链挑战和地缘政治风险。强调美国需通过AI基础设施保持竞争力。引用：“我们押注万亿美元基础设施，OpenAI可能是下一个超级玩家。”</td>
</tr>
<tr>
<td>1:05:00 - 1:20:00</td>
<td>OpenAI合作与AI代理未来</td>
<td>探讨NVIDIA与OpenAI、xAI等公司的合作，预测AI代理将重定义企业运营（如客服、物流）。强调加速计算的经济性：1美元GPU可替代100美元CPU。</td>
</tr>
<tr>
<td>1:20:00 - 1:35:00</td>
<td>美中科技竞争与全球格局</td>
<td>Huang分析中国在AI研究中的崛起（全球50%顶尖AI研究员来自中国），警告美国需加大教育和基础设施投资。讨论出口管制对NVIDIA的影响，强调“无限游戏”心态以保持技术领先。引用：“中国有惊人的工程师，我们必须跑得更快。”</td>
</tr>
<tr>
<td>1:35:00 - 1:43:38</td>
<td>个人故事与美国梦2.0</td>
<td>Huang分享移民经历（从泰国到美国），呼吁通过AI教育和创新重塑美国竞争力。鼓励年轻人拥抱编程和AI，展望AI驱动的“新工业革命”。结语：“AI是我们的登月计划，年轻人要抓住机会。”</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<h3>针对t=652s（10:52）的说明</h3>
<p>在视频的10:52处（652秒），访谈正处于“AI计算的演进与推理热潮”部分。Huang正在讨论NVIDIA的GPU如何通过并行计算（parallel computing）比传统CPU更高效地处理AI工作负载，特别提到推理（inference）需求的快速增长。他用类比解释GPU的计算密度优势，强调NVIDIA的芯片设计如何为AI时代奠定基础。</p>
<h2>推理芯片和训练芯片有什么不同？</h2>
<p>推理芯片（Inference Chips）和训练芯片（Training Chips）在AI计算中的设计目标和应用场景不同，主要区别源于它们在AI工作负载中的角色：训练芯片用于构建和优化AI模型，推理芯片用于在实际应用中运行已训练好的模型。以下是详细对比，结合NVIDIA CEO Jensen Huang在访谈（<a href="https://youtu.be/L75N-989B7E%EF%BC%89%E4%B8%AD%E7%9A%84%E7%9B%B8%E5%85%B3%E8%AE%A8%E8%AE%BA%EF%BC%9A" rel="nofollow">https://youtu.be/L75N-989B7E）中的相关讨论：</a></p>
<h3>1. <strong>功能与工作负载</strong></h3>
<ul>
<li>
<p><strong>训练芯片</strong>：</p>
<ul>
<li><strong>目的</strong>：用于AI模型的训练（Training），即通过大量数据和计算，优化模型参数（如神经网络权重）。</li>
<li><strong>工作负载</strong>：处理大规模矩阵运算（主要是浮点运算，如FP32或FP16），涉及梯度下降、反向传播等高计算密集任务。训练需要反复迭代，处理海量数据，优化模型以提高准确性。</li>
<li><strong>特点</strong>：强调高吞吐量和并行计算能力，能处理多样化、动态的计算任务。训练阶段通常对延迟不敏感，但需要极高的计算能力。</li>
<li><strong>例子</strong>：NVIDIA的H100、A100 GPU，专为训练大语言模型（如ChatGPT）设计，支持高精度计算和大规模数据并行。</li>
</ul>
</li>
<li>
<p><strong>推理芯片</strong>：</p>
<ul>
<li><strong>目的</strong>：用于AI模型的推理（Inference），即在实际应用中用已训练好的模型处理新输入，生成预测或输出（如语音识别、图像分类）。</li>
<li><strong>工作负载</strong>：主要执行前向传播（forward pass），处理单个或小批量输入，涉及矩阵乘法和激活函数。推理任务通常数据量较小，但对实时性要求高。</li>
<li><strong>特点</strong>：优化低延迟和高能效，适合实时或边缘设备场景（如手机、自动驾驶）。推理芯片常使用较低精度（如INT8或FP8）以提升速度和降低功耗。</li>
<li><strong>例子</strong>：NVIDIA的T4、Jetson系列，或推理优化的L4 GPU，广泛用于云端推理或边缘设备。</li>
</ul>
</li>
</ul>
<p><strong>访谈相关</strong>：Huang在视频（约10:00-15:00）提到，推理现占NVIDIA营收超40%，并预测推理需求将增长“10亿倍”，因为推理应用（如AI助手、推荐系统）正爆炸式增长，驱动了对低延迟芯片的需求。</p>
<h3>2. <strong>设计优化</strong></h3>
<ul>
<li>
<p><strong>训练芯片</strong>：</p>
<ul>
<li><strong>高计算能力</strong>：设计支持高精度浮点运算（如FP16/BF16）和大规模并行计算，配备大容量高带宽内存（如HBM3）。</li>
<li><strong>内存需求</strong>：需要大显存（几十GB）来存储模型参数、中间梯度和训练数据。</li>
<li><strong>能耗</strong>：功耗较高（数百瓦），因为训练通常在数据中心进行，优先考虑性能而非能效。</li>
<li><strong>架构</strong>：强调多核并行和通用计算能力，适合复杂、动态的训练任务。</li>
</ul>
</li>
<li>
<p><strong>推理芯片</strong>：</p>
<ul>
<li><strong>低延迟与高能效</strong>：优化快速响应和低功耗，适合边缘设备或实时应用。常使用量化（quantization）技术降低计算精度以提升速度。</li>
<li><strong>内存需求</strong>：显存需求较低（几GB即可），因为推理只加载预训练模型参数，处理单次输入。</li>
<li><strong>能耗</strong>：功耗较低（几十瓦或更低），适合移动设备或嵌入式系统。</li>
<li><strong>架构</strong>：简化计算单元，集成专用推理加速模块（如Tensor Cores的低精度模式）。</li>
</ul>
</li>
</ul>
<p><strong>访谈相关</strong>：Huang在50:00-1:05:00讨论“测试时计算”（Test-time Compute，即推理），强调推理芯片需支持链式思考（Chain-of-Thought），这要求芯片在实时性上优化，同时保持足够灵活性。</p>
<h3>3. <strong>应用场景</strong></h3>
<ul>
<li>
<p><strong>训练芯片</strong>：</p>
<ul>
<li>用于数据中心，训练大语言模型（如LLMs）、图像生成模型（如DALL-E）或科学计算（如蛋白质折叠）。</li>
<li>典型场景：OpenAI训练ChatGPT，Google训练Gemini，需超大规模集群（如Huang提到的10吉瓦“Stargate”项目）。</li>
<li>时间周期：训练可能耗时数周到数月，计算成本高。</li>
</ul>
</li>
<li>
<p><strong>推理芯片</strong>：</p>
<ul>
<li>用于云端（推荐系统、聊天机器人）、边缘设备（自动驾驶、手机AI）或嵌入式系统（智能摄像头）。</li>
<li>典型场景：Siri语音识别、Tesla自动驾驶实时决策、Netflix推荐算法。</li>
<li>时间周期：推理需毫秒级响应，强调实时性。</li>
</ul>
</li>
</ul>
<p><strong>访谈相关</strong>：Huang在25:00-35:00提到“AI工厂”概念，推理芯片是其核心，负责将训练好的模型转化为实时“智能输出”，如AI代理处理客服或物流任务。</p>
<h3>4. <strong>性能与成本权衡</strong></h3>
<ul>
<li>
<p><strong>训练芯片</strong>：</p>
<ul>
<li>性能优先，成本高（单颗H100 GPU价格可达数万美元）。</li>
<li>部署在大型数据中心，需配套高性能冷却和电源系统。</li>
<li>Huang提到（1:05:00-1:20:00），训练芯片的经济性在于“加速计算”：1美元GPU可替代100美元CPU。</li>
</ul>
</li>
<li>
<p><strong>推理芯片</strong>：</p>
<ul>
<li>平衡性能与成本，价格较低（T4或Jetson价格在千美元级或以下）。</li>
<li>适合边缘部署，需低功耗以适应电池供电或小型设备。</li>
<li>Huang强调（10:00-15:00），推理芯片的广泛部署推动了AI普及，如手机上的AI助手。</li>
</ul>
</li>
</ul>
<h3>5. <strong>技术挑战</strong></h3>
<ul>
<li><strong>训练芯片</strong>：
<ul>
<li>挑战：管理超大规模集群的同步和通信（如NVLink互联），处理数据并行和模型并行的复杂性。</li>
<li>能源需求：高功耗需匹配吉瓦级电力供应（如Huang的“10GW赌注”）。</li>
</ul>
</li>
<li><strong>推理芯片</strong>：
<ul>
<li>挑战：优化低精度计算以保持准确性，同时在边缘设备上应对内存和散热限制。</li>
<li>能源需求：需极低功耗以支持移动或嵌入式场景。</li>
</ul>
</li>
</ul>
<h3>总结</h3>
<markdown-accessiblity-table><table role="table">
<thead>
<tr>
<th>特性</th>
<th>训练芯片</th>
<th>推理芯片</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>目的</strong></td>
<td>构建/优化AI模型</td>
<td>运行已训练模型</td>
</tr>
<tr>
<td><strong>工作负载</strong></td>
<td>高精度矩阵运算、反向传播</td>
<td>前向传播、低精度推理</td>
</tr>
<tr>
<td><strong>性能重点</strong></td>
<td>高吞吐量、大显存</td>
<td>低延迟、高能效</td>
</tr>
<tr>
<td><strong>典型应用</strong></td>
<td>数据中心训练（如ChatGPT）</td>
<td>实时应用（如自动驾驶、AI助手）</td>
</tr>
<tr>
<td><strong>功耗</strong></td>
<td>高（数百瓦）</td>
<td>低（几十瓦或以下）</td>
</tr>
<tr>
<td><strong>例子</strong></td>
<td>NVIDIA H100, A100</td>
<td>NVIDIA T4, L4, Jetson</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p><strong>访谈洞察</strong>：Huang在视频中（35:00-50:00）提到，NVIDIA的芯片设计（如Hopper和Blackwell架构）同时支持训练和推理，但推理的爆炸式增长推动了专用优化（如低精度Tensor Cores）。他预测，未来“AI工厂”将依赖推理芯片的规模化部署，驱动万亿美元级产业。</p></div>
<div style="font-size:small;margin-top:8px;float:right;">© 版权所有</div>

<button class="btn btn-block" type="button" onclick="openComments()" id="cmButton">评论</button>
<div class="comments" id="comments"></div>

</div>
    <div id="footer"><div id="footer1">Copyright © <span id="copyrightYear"></span> <a href="https://ai.lxc.one">AI.LXC.ONE | 爱智体博客</a></div>
<div id="footer2">
    <span id="runday"></span><span>Powered by <a href="https://meekdai.com/Gmeek.html" target="_blank">Gmeek</a></span>
</div>

<script>
var now=new Date();
document.getElementById("copyrightYear").innerHTML=now.getFullYear();

if("04/04/2025"!=""){
    var startSite=new Date("04/04/2025");
    var diff=now.getTime()-startSite.getTime();
    var diffDay=Math.floor(diff/(1000*60*60*24));
    document.getElementById("runday").innerHTML="网站运行"+diffDay+"天"+" • ";
}
</script></div>
</body>
<script>
var IconList={'sun': 'M8 10.5a2.5 2.5 0 100-5 2.5 2.5 0 000 5zM8 12a4 4 0 100-8 4 4 0 000 8zM8 0a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0V.75A.75.75 0 018 0zm0 13a.75.75 0 01.75.75v1.5a.75.75 0 01-1.5 0v-1.5A.75.75 0 018 13zM2.343 2.343a.75.75 0 011.061 0l1.06 1.061a.75.75 0 01-1.06 1.06l-1.06-1.06a.75.75 0 010-1.06zm9.193 9.193a.75.75 0 011.06 0l1.061 1.06a.75.75 0 01-1.06 1.061l-1.061-1.06a.75.75 0 010-1.061zM16 8a.75.75 0 01-.75.75h-1.5a.75.75 0 010-1.5h1.5A.75.75 0 0116 8zM3 8a.75.75 0 01-.75.75H.75a.75.75 0 010-1.5h1.5A.75.75 0 013 8zm10.657-5.657a.75.75 0 010 1.061l-1.061 1.06a.75.75 0 11-1.06-1.06l1.06-1.06a.75.75 0 011.06 0zm-9.193 9.193a.75.75 0 010 1.06l-1.06 1.061a.75.75 0 11-1.061-1.06l1.06-1.061a.75.75 0 011.061 0z', 'moon': 'M9.598 1.591a.75.75 0 01.785-.175 7 7 0 11-8.967 8.967.75.75 0 01.961-.96 5.5 5.5 0 007.046-7.046.75.75 0 01.175-.786zm1.616 1.945a7 7 0 01-7.678 7.678 5.5 5.5 0 107.678-7.678z', 'sync': 'M1.705 8.005a.75.75 0 0 1 .834.656 5.5 5.5 0 0 0 9.592 2.97l-1.204-1.204a.25.25 0 0 1 .177-.427h3.646a.25.25 0 0 1 .25.25v3.646a.25.25 0 0 1-.427.177l-1.38-1.38A7.002 7.002 0 0 1 1.05 8.84a.75.75 0 0 1 .656-.834ZM8 2.5a5.487 5.487 0 0 0-4.131 1.869l1.204 1.204A.25.25 0 0 1 4.896 6H1.25A.25.25 0 0 1 1 5.75V2.104a.25.25 0 0 1 .427-.177l1.38 1.38A7.002 7.002 0 0 1 14.95 7.16a.75.75 0 0 1-1.49.178A5.5 5.5 0 0 0 8 2.5Z', 'home': 'M6.906.664a1.749 1.749 0 0 1 2.187 0l5.25 4.2c.415.332.657.835.657 1.367v7.019A1.75 1.75 0 0 1 13.25 15h-3.5a.75.75 0 0 1-.75-.75V9H7v5.25a.75.75 0 0 1-.75.75h-3.5A1.75 1.75 0 0 1 1 13.25V6.23c0-.531.242-1.034.657-1.366l5.25-4.2Zm1.25 1.171a.25.25 0 0 0-.312 0l-5.25 4.2a.25.25 0 0 0-.094.196v7.019c0 .138.112.25.25.25H5.5V8.25a.75.75 0 0 1 .75-.75h3.5a.75.75 0 0 1 .75.75v5.25h2.75a.25.25 0 0 0 .25-.25V6.23a.25.25 0 0 0-.094-.195Z', 'github': 'M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z'};
var utterancesLoad=0;

let themeSettings={
    "dark": ["dark","moon","#00f0ff","dark-blue"],
    "light": ["light","sun","#ff5000","github-light"],
    "auto": ["auto","sync","","preferred-color-scheme"]
};
function changeTheme(mode, icon, color, utheme){
    document.documentElement.setAttribute("data-color-mode",mode);
    document.getElementById("themeSwitch").setAttribute("d",value=IconList[icon]);
    document.getElementById("themeSwitch").parentNode.style.color=color;
    if(utterancesLoad==1){utterancesTheme(utheme);}
}
function modeSwitch(){
    let currentMode=document.documentElement.getAttribute('data-color-mode');
    let newMode = currentMode === "light" ? "dark" : currentMode === "dark" ? "auto" : "light";
    localStorage.setItem("meek_theme", newMode);
    if(themeSettings[newMode]){
        changeTheme(...themeSettings[newMode]);
    }
}
function utterancesTheme(theme){
    const message={type:'set-theme',theme: theme};
    const iframe=document.getElementsByClassName('utterances-frame')[0];
    iframe.contentWindow.postMessage(message,'https://utteranc.es');
}
if(themeSettings[theme]){changeTheme(...themeSettings[theme]);}
console.log("\n %c Gmeek last https://github.com/Meekdai/Gmeek \n","padding:5px 0;background:#02d81d;color:#fff");
</script>

<script>
document.getElementById("pathHome").setAttribute("d",IconList["home"]);
document.getElementById("pathIssue").setAttribute("d",IconList["github"]);



function openComments(){
    cm=document.getElementById("comments");
    cmButton=document.getElementById("cmButton");
    cmButton.innerHTML="loading";
    span=document.createElement("span");
    span.setAttribute("class","AnimatedEllipsis");
    cmButton.appendChild(span);

    script=document.createElement("script");
    script.setAttribute("src","https://utteranc.es/client.js");
    script.setAttribute("repo","lxc-one/lxc-one.github.io");
    script.setAttribute("issue-term","title");
    
    if(localStorage.getItem("meek_theme")=="dark"){script.setAttribute("theme","dark-blue");}
    else if(localStorage.getItem("meek_theme")=="light") {script.setAttribute("theme","github-light");}
    else{script.setAttribute("theme","preferred-color-scheme");}
    
    script.setAttribute("crossorigin","anonymous");
    script.setAttribute("async","");
    cm.appendChild(script);

    int=self.setInterval("iFrameLoading()",200);
}

function iFrameLoading(){
    var utterances=document.getElementsByClassName('utterances');
    if(utterances.length==1){
        if(utterances[0].style.height!=""){
            utterancesLoad=1;
            int=window.clearInterval(int);
            document.getElementById("cmButton").style.display="none";
            console.log("utterances Load OK");
        }
    }
}



</script>
<script async src='//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js'></script><script src='https://ai.lxc.one/articletoc.js'></script>

</html>
